{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 754,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import math\n",
    "import random\n",
    "import cPickle\n",
    "import collections\n",
    "import nltk\n",
    "import scipy.stats\n",
    "import scipy as sp\n",
    "from nltk.corpus import stopwords\n",
    "from textblob import TextBlob as tb\n",
    "import collections\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=========================test full vocabulary=============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61188\n"
     ]
    }
   ],
   "source": [
    "# load vocabulary.txt and store it in an array\n",
    "fv=open('/Users/weiweili/Documents/UCSD-Stats/CSE 250B Fall16/HW2/vocabulary.txt','r')\n",
    "vb=[]\n",
    "for line in fv.readlines():\n",
    "    b=line.strip()\n",
    "    vb.append(b)\n",
    "    \n",
    "fv.close()\n",
    "\n",
    "vb_num=len(vb)\n",
    "print vb_num\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11269\n"
     ]
    }
   ],
   "source": [
    "# load tain.label\n",
    "frl=open('/Users/weiweili/Documents/UCSD-Stats/CSE 250B Fall16/HW2/20news-bydate/matlab/train.label','r')\n",
    "trn_l=[]\n",
    "for line in frl.readlines():\n",
    "    b=int(line.strip())\n",
    "    trn_l.append(b)\n",
    "    \n",
    "frl.close()\n",
    "    \n",
    "doc_num=len(trn_l)\n",
    "print doc_num\n",
    "#print trn_l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7505\n"
     ]
    }
   ],
   "source": [
    "# load test.label\n",
    "fsl=open('/Users/weiweili/Documents/UCSD-Stats/CSE 250B Fall16/HW2/20news-bydate/matlab/test.label','r')\n",
    "tst_l=[]\n",
    "for line in fsl.readlines():\n",
    "    b=int(line.strip())\n",
    "    tst_l.append(b)\n",
    "fsl.close()\n",
    "print len(tst_l)\n",
    "#print tst_l\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11269, 61188)\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  1.]\n"
     ]
    }
   ],
   "source": [
    "# load train.data\n",
    "frd=open('/Users/weiweili/Documents/UCSD-Stats/CSE 250B Fall16/HW2/20news-bydate/matlab/train.data','r')\n",
    "trn_matrix=np.zeros([doc_num,vb_num])\n",
    "for line in frd.readlines():\n",
    "    b = line.strip().split()     #train.data formatted as \"docIdx wordIdx count\", b[0]=docIdx; b[1]=wordIdx; b[2]=count\n",
    "    if(len(b) != 3):\n",
    "        print \"data missing\"\n",
    "    trn_matrix[int(b[0])-1][int(b[1])-1] = int(b[2])  #b[0]=docIdx: 1,2,3,....\n",
    "frd.close()\n",
    "\n",
    "print trn_matrix.shape\n",
    "print trn_matrix[11268][53950:53958]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7505, 61188)\n",
      "[ 0.  0.  0. ...,  0.  0.  2.]\n"
     ]
    }
   ],
   "source": [
    "# load test.data\n",
    "tst_matrix=np.zeros([len(tst_l),vb_num])\n",
    "fsd=open('/Users/weiweili/Documents/UCSD-Stats/CSE 250B Fall16/HW2/20news-bydate/matlab/test.data','r')\n",
    "for line in fsd.readlines():\n",
    "    b = line.strip().split()\n",
    "    if (len(b) !=3):\n",
    "        print \"data missing\"\n",
    "    tst_matrix[int(b[0])-1][int(b[1])-1]=int(b[2])\n",
    "        \n",
    "fsd.close()\n",
    "\n",
    "print tst_matrix.shape\n",
    "print tst_matrix[7504]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 148812.0), (2, 110358.0), (3, 90767.0), (4, 99146.0), (5, 86190.0), (6, 152846.0), (7, 61094.0), (8, 114102.0), (9, 102631.0), (10, 107898.0), (11, 141267.0), (12, 200456.0), (13, 103173.0), (14, 155338.0), (15, 153714.0), (16, 201267.0), (17, 175914.0), (18, 254805.0), (19, 186426.0), (20, 119096.0)]\n"
     ]
    }
   ],
   "source": [
    "# n_j: 20*2 the matrix of the sum of words in class j\n",
    "nj=collections.defaultdict(int)\n",
    "for i in range (doc_num):\n",
    "    if trn_l[i] in nj:         #doc_num = 11269, only 20 classes\n",
    "        nj[trn_l[i]] += np.sum(trn_matrix[i]) \n",
    "    else:\n",
    "        nj[trn_l[i]] = np.sum(trn_matrix[i])\n",
    "        \n",
    "print nj.items()\n",
    "# nj[key]: key=1,2,...,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 61187\n",
      "500 61187\n",
      "1000 61187\n",
      "1500 61187\n",
      "2000 61187\n",
      "2500 61187\n",
      "3000 61187\n",
      "3500 61187\n",
      "4000 61187\n",
      "4500 61187\n",
      "5000 61187\n",
      "5500 61187\n",
      "6000 61187\n",
      "6500 61187\n",
      "7000 61187\n",
      "7500 61187\n",
      "8000 61187\n",
      "8500 61187\n",
      "9000 61187\n",
      "9500 61187\n",
      "10000 61187\n",
      "10500 61187\n",
      "11000 61187\n"
     ]
    }
   ],
   "source": [
    "# n_{jw}: 20*vb_num #the matrix of the number of word 'w' in class j\n",
    "K = 20\n",
    "n_jw = np.zeros([K, vb_num])\n",
    "for i in range(doc_num):\n",
    "    for j in range(vb_num):\n",
    "        if i % 500 == 0 and j == (vb_num-1):    \n",
    "            print i,j\n",
    "        n_jw[trn_l[i]-1][j] += trn_matrix[i][j]                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {1: 480, 2: 581, 3: 572, 4: 587, 5: 575, 6: 592, 7: 582, 8: 592, 9: 596, 10: 594, 11: 598, 12: 594, 13: 591, 14: 594, 15: 593, 16: 599, 17: 545, 18: 564, 19: 464, 20: 376})\n",
      "1.0 defaultdict(<type 'int'>, {1: 0.04259472890229834, 2: 0.05155736977549028, 3: 0.05075871860857219, 4: 0.05208980388676901, 5: 0.051024935664211554, 6: 0.052533498979501284, 7: 0.051646108794036735, 8: 0.052533498979501284, 9: 0.052888455053687104, 10: 0.0527109770165942, 11: 0.05306593309078002, 12: 0.0527109770165942, 13: 0.05244475996095483, 14: 0.0527109770165942, 15: 0.052622237998047744, 16: 0.05315467210932647, 17: 0.04836276510781791, 18: 0.05004880646020055, 19: 0.04117490460555506, 20: 0.033365870973467035})\n"
     ]
    }
   ],
   "source": [
    "# hj: the probability of each class\n",
    "hj=collections.defaultdict(int)\n",
    "for i in range(doc_num):\n",
    "    if trn_l[i] in hj:\n",
    "        hj[trn_l[i]] += 1\n",
    "    else:\n",
    "        hj[trn_l[i]] = 1\n",
    "print hj\n",
    "s=0\n",
    "for key in hj:\n",
    "    hj[key]= hj[key]*1.0/doc_num\n",
    "    \n",
    "    s +=hj[key]   #check if the sum is 0\n",
    "print s,hj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-3.15602476805\n",
      "-2.9650601151\n",
      "-2.98067188057\n",
      "-2.95478605212\n",
      "-2.97544083115\n",
      "-2.94630423707\n",
      "-2.96334042422\n",
      "-2.94630423707\n",
      "-2.93957020489\n",
      "-2.94293155259\n",
      "-2.936220118\n",
      "-2.94293155259\n",
      "-2.94799485455\n",
      "-2.94293155259\n",
      "-2.94461647295\n",
      "-2.93454927384\n",
      "-3.02902507729\n",
      "-2.99475662045\n",
      "-3.18992631973\n",
      "-3.40022172856\n"
     ]
    }
   ],
   "source": [
    "log_hj=collections.defaultdict(int)\n",
    "for key in hj:\n",
    "    log_hj[key] = math.log(hj[key])\n",
    "    #print log_hj[key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#calculate P_jw with smoothing\n",
    "p_jw=np.zeros([K,vb_num])\n",
    "for j in range(K):\n",
    "    for w in range(vb_num):\n",
    "        p_jw[j][w]=(n_jw[j][w]+1)*1.0/(nj[j+1]+vb_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# use logs to avoid underflow\n",
    "log_p_jw=np.zeros([K,vb_num])\n",
    "for j in range(K):\n",
    "    for w in range(vb_num):\n",
    "        log_p_jw[j][w]=math.log(p_jw[j][w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of correctly classified: 5862\n",
      "error rate:  0.21892071952\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "correct_classified = 0\n",
    "for i in range(len(tst_l)):\n",
    "    predict = 0\n",
    "    max_val = float('-Inf')\n",
    "    for k in range(K):\n",
    "        tmp = log_hj[k+1]\n",
    "        tmp += np.dot(tst_matrix[i], log_p_jw[k])  #sum of log(P_ki ^ xi)\n",
    "        #for j in range(V):\n",
    "        #    tmp += test_matrix[i][j] * log_prob[k][j]\n",
    "        if tmp > max_val:\n",
    "            max_val = tmp\n",
    "            predict = k+1\n",
    "    if predict == tst_l[i]:\n",
    "        correct_classified += 1\n",
    "print 'the number of correctly classified:', correct_classified\n",
    "print \"error rate: \", 1 - correct_classified * 1.0 / len(tst_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#==========================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save results\n",
    "cPickle.dump(hj, open('hj.pkl','wb'))\n",
    "cPickle.dump(p_jw, open('p_jw.pkl','wb'))\n",
    "cPickle.dump(log_hj, open('log_hj.pkl','wb'))\n",
    "cPickle.dump(log_p_jw, open('log_p_jw.pkl','wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#================================reduced_voca withou stopwords===================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/weiweili/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "import nltk; nltk.download(\"stopwords\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#nltk.download()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61044\n"
     ]
    }
   ],
   "source": [
    "# reduce vocabulary by reducing stopwords\n",
    "reduced_voca = []\n",
    "stopwords = stopwords.words('english')\n",
    "fv=open('/Users/weiweili/Documents/UCSD-Stats/CSE 250B Fall16/HW2/vocabulary.txt','r')\n",
    "for line in fv.readlines():\n",
    "    b = line.strip()\n",
    "    if not b in stopwords:\n",
    "        reduced_voca.append(b)\n",
    "fv.close()\n",
    "num_rvb= len(reduced_voca)\n",
    "print num_rvb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 353,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vb_index=np.zeros([num_rvb])\n",
    "for j in range(num_rvb):\n",
    "    vb_index[j]= vb.index(reduced_voca[j])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 61043\n",
      "500 61043\n",
      "1000 61043\n",
      "1500 61043\n",
      "2000 61043\n",
      "2500 61043\n",
      "3000 61043\n",
      "3500 61043\n",
      "4000 61043\n",
      "4500 61043\n",
      "5000 61043\n",
      "5500 61043\n",
      "6000 61043\n",
      "6500 61043\n",
      "7000 61043\n",
      "7500 61043\n"
     ]
    }
   ],
   "source": [
    "# test matrix for reduced vocab\n",
    "n_tst_matrix = np.zeros([len(tst_l),num_rvb])\n",
    "for i in range(len(tst_l)):\n",
    "    for j in range(num_rvb):\n",
    "        if i % 500 == 0 and j == (num_rvb-1):    \n",
    "            print i,j\n",
    "        n_tst_matrix[i][j] = tst_matrix[i][int(vb_index[j])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 61043\n",
      "500 61043\n",
      "1000 61043\n",
      "1500 61043\n",
      "2000 61043\n",
      "2500 61043\n",
      "3000 61043\n",
      "3500 61043\n",
      "4000 61043\n",
      "4500 61043\n",
      "5000 61043\n",
      "5500 61043\n",
      "6000 61043\n",
      "6500 61043\n",
      "7000 61043\n",
      "7500 61043\n",
      "8000 61043\n",
      "8500 61043\n",
      "9000 61043\n",
      "9500 61043\n",
      "10000 61043\n",
      "10500 61043\n",
      "11000 61043\n"
     ]
    }
   ],
   "source": [
    "# train matrix for reduced vocab\n",
    "n_trn_matrix = np.zeros([len(trn_l),num_rvb])\n",
    "for i in range(len(trn_l)):\n",
    "    for j in range(num_rvb):\n",
    "        if i % 500 == 0 and j == (num_rvb-1):    \n",
    "            print i,j\n",
    "        n_trn_matrix[i][j] = trn_matrix[i][int(vb_index[j])]\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 357,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 78618.0), (2, 69489.0), (3, 56845.0), (4, 59876.0), (5, 50837.0), (6, 96306.0), (7, 41757.0), (8, 64991.0), (9, 61026.0), (10, 63397.0), (11, 88599.0), (12, 116774.0), (13, 60943.0), (14, 91403.0), (15, 94858.0), (16, 102430.0), (17, 98629.0), (18, 137147.0), (19, 101027.0), (20, 63228.0)]\n"
     ]
    }
   ],
   "source": [
    "# n_j for reduced vocab: 20*20 the matrix of the sum of words in class j\n",
    "nj=collections.defaultdict(int)\n",
    "for i in range (doc_num):\n",
    "    if trn_l[i] in nj:\n",
    "        nj[trn_l[i]] += np.sum(n_trn_matrix[i]) \n",
    "    else:\n",
    "        nj[trn_l[i]] = np.sum(n_trn_matrix[i])\n",
    "        \n",
    "print nj.items()\n",
    "# nj[key]: key=1,2,...,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 359,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 61043\n",
      "500 61043\n",
      "1000 61043\n",
      "1500 61043\n",
      "2000 61043\n",
      "2500 61043\n",
      "3000 61043\n",
      "3500 61043\n",
      "4000 61043\n",
      "4500 61043\n",
      "5000 61043\n",
      "5500 61043\n",
      "6000 61043\n",
      "6500 61043\n",
      "7000 61043\n",
      "7500 61043\n",
      "8000 61043\n",
      "8500 61043\n",
      "9000 61043\n",
      "9500 61043\n",
      "10000 61043\n",
      "10500 61043\n",
      "11000 61043\n"
     ]
    }
   ],
   "source": [
    "# n_{jw}: 20*vb_num #the matrix of the number of word 'w' in class j\n",
    "K = 20\n",
    "n_jw = np.zeros([K, num_rvb])\n",
    "for i in range(doc_num):\n",
    "    for j in range(num_rvb):\n",
    "        if i % 500 == 0 and j == (num_rvb-1):    \n",
    "            print i,j\n",
    "        n_jw[trn_l[i]-1][j] += n_trn_matrix[i][j]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 355,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate P_jw with smoothing\n",
    "p_jw=np.zeros([K,num_rvb])\n",
    "for j in range(K):\n",
    "    for w in range(num_rvb):\n",
    "        p_jw[j][w]=(n_jw[j][w]+1)*1.0/(nj[j+1]+num_rvb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use logs to avoid underflow\n",
    "log_p_jw=np.zeros([K,num_rvb])\n",
    "for j in range(K):\n",
    "    for w in range(num_rvb):\n",
    "        log_p_jw[j][w]=math.log(p_jw[j][w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 365,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 61044)\n"
     ]
    }
   ],
   "source": [
    "print log_p_jw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of correctly classified: 6010\n",
      "error rate:  0.199200532978\n"
     ]
    }
   ],
   "source": [
    "# test\n",
    "correct_classified = 0\n",
    "for i in range(len(tst_l)):\n",
    "    predict = 0\n",
    "    max_val = float('-Inf')\n",
    "    for k in range(K):\n",
    "        tmp = log_hj[k+1]\n",
    "        tmp += np.dot(n_tst_matrix[i], log_p_jw[k])  #sum of log(P_jw ^ xi)\n",
    "        if tmp > max_val:\n",
    "            max_val = tmp\n",
    "            predict = k+1\n",
    "    if predict == tst_l[i]:\n",
    "        correct_classified += 1\n",
    "print 'the number of correctly classified:', correct_classified\n",
    "print \"error rate: \", 1 - correct_classified * 1.0 / len(tst_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#================Calculate CI for Random selection from reduced_voca==============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate CI:\n",
    "def mean_confidence_interval(data, confidence=0.95):\n",
    "    a = 1.0*np.array(data)\n",
    "    n = len(a)\n",
    "    c, se = np.mean(a), scipy.stats.sem(a)\n",
    "    h = se * sp.stats.t._ppf((1+confidence)/2., n-1)\n",
    "    return c,h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 753,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "[[0.56735509660226513, nan]]\n"
     ]
    }
   ],
   "source": [
    "#random selectin from reduced voca \n",
    "M=[5000,10000,20000]\n",
    "CI=[]\n",
    "for m in M:\n",
    "    rd_error=[]\n",
    "    for n in range(50):\n",
    "        rsvb=np.random.choice(reduced_voca,m)\n",
    "        rsvb_index=np.zeros([m])\n",
    "        for j in range(m):\n",
    "            rsvb_index[j]= reduced_voca.index(rsvb[j])\n",
    "        \n",
    "        \n",
    "        # train matrix\n",
    "        rn_trn_matrix = np.zeros([len(trn_l),m])\n",
    "        for i in range(len(trn_l)):\n",
    "            for j in range(m):\n",
    "                rn_trn_matrix[i][j] = n_trn_matrix[i][int(rsvb_index[j])]\n",
    "        \n",
    "        \n",
    "        #test matrix        \n",
    "        rn_tst_matrix = np.zeros([len(tst_l),m])\n",
    "        for i in range(len(tst_l)):\n",
    "            for j in range(m):\n",
    "                rn_tst_matrix[i][j] = n_tst_matrix[i][int(rsvb_index[j])]\n",
    "        \n",
    "        \n",
    "        #n_j\n",
    "        nj=collections.defaultdict(int)\n",
    "        for i in range (doc_num):\n",
    "            if trn_l[i] in nj:\n",
    "                nj[trn_l[i]] += np.sum(rn_trn_matrix[i]) \n",
    "            else:\n",
    "                nj[trn_l[i]] = np.sum(rn_trn_matrix[i])\n",
    "                \n",
    "                    \n",
    "        # n_{jw}: 20*m #the matrix of the number of word 'w' in class j\n",
    "        K = 20\n",
    "        n_jw = np.zeros([K, m])\n",
    "        for i in range(doc_num):\n",
    "            for j in range(m):\n",
    "                n_jw[trn_l[i]-1][j] += rn_trn_matrix[i][j]    \n",
    "                \n",
    "                \n",
    "        #calculate P_jw with smoothing\n",
    "        K=20\n",
    "        p_jw=np.zeros([K,m])\n",
    "        for j in range(K):\n",
    "            for w in range(m):\n",
    "                p_jw[j][w]=(n_jw[j][w]+1)*1.0/(nj[j+1]+m)\n",
    "    \n",
    "                \n",
    "        # use logs to avoid underflow\n",
    "        log_p_jw=np.zeros([K,m])\n",
    "        for j in range(K):\n",
    "            for w in range(m):\n",
    "                log_p_jw[j][w]=math.log(p_jw[j][w])\n",
    "        \n",
    "        # test for random selctected reduced_voca\n",
    "        correct_classified = 0\n",
    "        for i in range(len(tst_l)):\n",
    "            predict = 0\n",
    "            max_val = float('-Inf')\n",
    "            for k in range(K):\n",
    "                tmp = log_hj[k+1]\n",
    "                tmp += np.dot(rn_tst_matrix[i], log_p_jw[k])  #sum of log(P_jw ^ xi)\n",
    "\n",
    "                if tmp > max_val:\n",
    "                    max_val = tmp\n",
    "                    predict = k+1\n",
    "            if predict == tst_l[i]:\n",
    "                correct_classified += 1\n",
    "        #print 'the number of correctly classified:', correct_classified\n",
    "        error=1 - correct_classified * 1.0 / len(tst_l)\n",
    "        rd_error.append(error)\n",
    "        print n\n",
    "    print m\n",
    "    c=mean_confidence_interval(rd_error, confidence=0.95 )[0]\n",
    "    h=mean_confidence_interval(rd_error, confidence=0.95 )[1]\n",
    "    CI.append([c,h])\n",
    "print CI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==================random selection from reduced_voca======================"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 371,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5000,)\n",
      "[ 13295.  29734.  23505.  36039.  40832.  47367.  44614.  15639.  22546.\n",
      "  59945.  11607.  48054.  48503.  56802.   7452.  26099.  56990.  19989.\n",
      "  58506.  41856.   5379.  39821.  19252.   7531.   3695.  23951.  56580.\n",
      "  35072.  30576.  45669.  44770.  36507.  59384.  14880.   6040.  22134.\n",
      "  24218.   6326.   9790.  39316.  38262.  53462.  11652.  34809.   1669.\n",
      "  41261.  31459.  11369.   9401.  40138.]\n"
     ]
    }
   ],
   "source": [
    "#randomly select m from reduced_voca\n",
    "m=5000\n",
    "rsvb=np.random.choice(reduced_voca,m)\n",
    "rsvb_index=np.zeros([m])\n",
    "for j in range(m):\n",
    "    rsvb_index[j]= reduced_voca.index(rsvb[j])\n",
    "print rsvb_index.shape\n",
    "print rsvb_index[0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 372,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4999\n",
      "500 4999\n",
      "1000 4999\n",
      "1500 4999\n",
      "2000 4999\n",
      "2500 4999\n",
      "3000 4999\n",
      "3500 4999\n",
      "4000 4999\n",
      "4500 4999\n",
      "5000 4999\n",
      "5500 4999\n",
      "6000 4999\n",
      "6500 4999\n",
      "7000 4999\n",
      "7500 4999\n",
      "8000 4999\n",
      "8500 4999\n",
      "9000 4999\n",
      "9500 4999\n",
      "10000 4999\n",
      "10500 4999\n",
      "11000 4999\n"
     ]
    }
   ],
   "source": [
    "# train matrix for reduced vocab\n",
    "rn_trn_matrix = np.zeros([len(trn_l),m])\n",
    "for i in range(len(trn_l)):\n",
    "    for j in range(m):\n",
    "        if i % 500 == 0 and j == (m-1):    \n",
    "            print i,j\n",
    "        rn_trn_matrix[i][j] = n_trn_matrix[i][int(rsvb_index[j])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4999\n",
      "500 4999\n",
      "1000 4999\n",
      "1500 4999\n",
      "2000 4999\n",
      "2500 4999\n",
      "3000 4999\n",
      "3500 4999\n",
      "4000 4999\n",
      "4500 4999\n",
      "5000 4999\n",
      "5500 4999\n",
      "6000 4999\n",
      "6500 4999\n",
      "7000 4999\n",
      "7500 4999\n"
     ]
    }
   ],
   "source": [
    "## test matrix for random selceted reduced vocab\n",
    "rn_tst_matrix = np.zeros([len(tst_l),m])\n",
    "for i in range(len(tst_l)):\n",
    "    for j in range(m):\n",
    "        if i % 500 == 0 and j == (m-1):    \n",
    "            print i,j\n",
    "        rn_tst_matrix[i][j] = n_tst_matrix[i][int(rsvb_index[j])]\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 378,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(1, 5631.0), (2, 5111.0), (3, 4592.0), (4, 4409.0), (5, 3942.0), (6, 7727.0), (7, 3298.0), (8, 5354.0), (9, 4358.0), (10, 4403.0), (11, 6077.0), (12, 9465.0), (13, 4226.0), (14, 6979.0), (15, 7273.0), (16, 7522.0), (17, 7947.0), (18, 10609.0), (19, 7220.0), (20, 4675.0)]\n"
     ]
    }
   ],
   "source": [
    "# n_j for random selected reduced vocab: 20*20 the matrix of the sum of words in class j\n",
    "nj=collections.defaultdict(int)\n",
    "for i in range (doc_num):\n",
    "    if trn_l[i] in nj:\n",
    "        nj[trn_l[i]] += np.sum(rn_trn_matrix[i]) \n",
    "    else:\n",
    "        nj[trn_l[i]] = np.sum(rn_trn_matrix[i])\n",
    "        \n",
    "print nj.items()\n",
    "# nj[key]: key=1,2,...,20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 4999\n",
      "500 4999\n",
      "1000 4999\n",
      "1500 4999\n",
      "2000 4999\n",
      "2500 4999\n",
      "3000 4999\n",
      "3500 4999\n",
      "4000 4999\n",
      "4500 4999\n",
      "5000 4999\n",
      "5500 4999\n",
      "6000 4999\n",
      "6500 4999\n",
      "7000 4999\n",
      "7500 4999\n",
      "8000 4999\n",
      "8500 4999\n",
      "9000 4999\n",
      "9500 4999\n",
      "10000 4999\n",
      "10500 4999\n",
      "11000 4999\n"
     ]
    }
   ],
   "source": [
    "# n_{jw}: 20*m #the matrix of the number of word 'w' in class j\n",
    "K = 20\n",
    "n_jw = np.zeros([K, m])\n",
    "for i in range(doc_num):\n",
    "    for j in range(m):\n",
    "        if i % 500 == 0 and j == (m-1):    \n",
    "            print i,j\n",
    "        n_jw[trn_l[i]-1][j] += rn_trn_matrix[i][j]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate P_jw with smoothing\n",
    "K=20 \n",
    "p_jw=np.zeros([K,m])\n",
    "for j in range(K):\n",
    "    for w in range(m):\n",
    "        p_jw[j][w]=(n_jw[j][w]+1)*1.0/(nj[j+1]+m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use logs to avoid underflow\n",
    "log_p_jw=np.zeros([K,m])\n",
    "for j in range(K):\n",
    "    for w in range(m):\n",
    "        log_p_jw[j][w]=math.log(p_jw[j][w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of correctly classified: 3408\n",
      "error rate:  0.545902731512\n"
     ]
    }
   ],
   "source": [
    "# test for random selctected reduced_voca\n",
    "correct_classified = 0\n",
    "for i in range(len(tst_l)):\n",
    "    predict = 0\n",
    "    max_val = float('-Inf')\n",
    "    for k in range(K):\n",
    "        tmp = log_hj[k+1]\n",
    "        tmp += np.dot(rn_tst_matrix[i], log_p_jw[k])  #sum of log(P_jw ^ xi)\n",
    "        \n",
    "        if tmp > max_val:\n",
    "            max_val = tmp\n",
    "            predict = k+1\n",
    "    \n",
    "    if predict == tst_l[i]:\n",
    "        correct_classified += 1\n",
    "  \n",
    "print \"the number of correctly classified:\", correct_classified\n",
    "print \"error rate: \", 1 - correct_classified * 1.0 / len(tst_l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=============================vocab select by tf-idf============================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#==========use formula for Tfidf========="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 841,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 61043\n",
      "500 61043\n",
      "1000 61043\n",
      "1500 61043\n",
      "2000 61043\n",
      "2500 61043\n",
      "3000 61043\n",
      "3500 61043\n",
      "4000 61043\n",
      "4500 61043\n",
      "5000 61043\n",
      "5500 61043\n",
      "6000 61043\n",
      "6500 61043\n",
      "7000 61043\n",
      "7500 61043\n",
      "8000 61043\n",
      "8500 61043\n",
      "9000 61043\n",
      "9500 61043\n",
      "10000 61043\n",
      "10500 61043\n",
      "11000 61043\n"
     ]
    }
   ],
   "source": [
    "# n_{jw}: 20*vb_num #the matrix of the number of word 'w' in class j\n",
    "K = 20\n",
    "n_jw = np.zeros([K, num_rvb])\n",
    "for i in range(doc_num):\n",
    "    for j in range(num_rvb):\n",
    "        if i % 500 == 0 and j == (num_rvb-1):    \n",
    "            print i,j\n",
    "        n_jw[trn_l[i]-1][j] += n_trn_matrix[i][j]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 842,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "transformer = TfidfTransformer()  \n",
    "X = transformer.fit_transform(n_jw)\n",
    "tfidf_matrix=X.toarray()     #20x61044"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 812,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "print len(tfidf_matrix[:,0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#=========================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 843,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the max tfidf for each word in 20 classes\n",
    "max_tfidf=[]\n",
    "for i in range (num_rvb):\n",
    "    max_tfidf.append(max(tfidf_matrix[:,i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 760,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "61044\n"
     ]
    }
   ],
   "source": [
    "print len(max_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 869,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m=20000\n",
    "\n",
    "sorted_words = sorted(enumerate(max_tfidf), key=lambda x: x[1], reverse=True)[0:m]\n",
    "sorted_index=[item[0] for item in sorted_words]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 871,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20000\n"
     ]
    }
   ],
   "source": [
    "print len(sorted_index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 872,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19999\n",
      "500 19999\n",
      "1000 19999\n",
      "1500 19999\n",
      "2000 19999\n",
      "2500 19999\n",
      "3000 19999\n",
      "3500 19999\n",
      "4000 19999\n",
      "4500 19999\n",
      "5000 19999\n",
      "5500 19999\n",
      "6000 19999\n",
      "6500 19999\n",
      "7000 19999\n",
      "7500 19999\n",
      "8000 19999\n",
      "8500 19999\n",
      "9000 19999\n",
      "9500 19999\n",
      "10000 19999\n",
      "10500 19999\n",
      "11000 19999\n"
     ]
    }
   ],
   "source": [
    "# train matrix\n",
    "v_trn_matrix = np.zeros([len(trn_l),m])\n",
    "for i in range(len(trn_l)):\n",
    "    for j in range(m):\n",
    "        if i % 500 == 0 and j == (m-1):    \n",
    "            print i,j\n",
    "        v_trn_matrix[i][j] = n_trn_matrix[i][int(sorted_index[j])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 873,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19999\n",
      "500 19999\n",
      "1000 19999\n",
      "1500 19999\n",
      "2000 19999\n",
      "2500 19999\n",
      "3000 19999\n",
      "3500 19999\n",
      "4000 19999\n",
      "4500 19999\n",
      "5000 19999\n",
      "5500 19999\n",
      "6000 19999\n",
      "6500 19999\n",
      "7000 19999\n",
      "7500 19999\n"
     ]
    }
   ],
   "source": [
    "#test matrix        \n",
    "v_tst_matrix = np.zeros([len(tst_l),m])\n",
    "for i in range(len(tst_l)):\n",
    "    for j in range(m):\n",
    "        if i % 500 == 0 and j == (m-1):    \n",
    "            print i,j\n",
    "\n",
    "        v_tst_matrix[i][j] = n_tst_matrix[i][int(sorted_index[j])]\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 874,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#n_j\n",
    "nj=collections.defaultdict(int)\n",
    "for i in range (doc_num):\n",
    "    if trn_l[i] in nj:\n",
    "        nj[trn_l[i]] += np.sum(v_trn_matrix[i]) \n",
    "    else:\n",
    "        nj[trn_l[i]] = np.sum(v_trn_matrix[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 729,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defaultdict(<type 'int'>, {1: 50015.0, 2: 62286.0, 3: 41724.0, 4: 45388.0, 5: 38151.0, 6: 70904.0, 7: 27968.0, 8: 41521.0, 9: 36316.0, 10: 37746.0, 11: 47181.0, 12: 75682.0, 13: 40290.0, 14: 52747.0, 15: 59992.0, 16: 62464.0, 17: 58214.0, 18: 72076.0, 19: 61039.0, 20: 37183.0})\n"
     ]
    }
   ],
   "source": [
    "print nj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 875,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 19999\n",
      "500 19999\n",
      "1000 19999\n",
      "1500 19999\n",
      "2000 19999\n",
      "2500 19999\n",
      "3000 19999\n",
      "3500 19999\n",
      "4000 19999\n",
      "4500 19999\n",
      "5000 19999\n",
      "5500 19999\n",
      "6000 19999\n",
      "6500 19999\n",
      "7000 19999\n",
      "7500 19999\n",
      "8000 19999\n",
      "8500 19999\n",
      "9000 19999\n",
      "9500 19999\n",
      "10000 19999\n",
      "10500 19999\n",
      "11000 19999\n"
     ]
    }
   ],
   "source": [
    "# n_{jw}: 20*m #the matrix of the number of word 'w' in class j\n",
    "K = 20\n",
    "n_jw = np.zeros([K, m])\n",
    "for i in range(doc_num):\n",
    "    for j in range(m):\n",
    "        if i % 500 == 0 and j == (m-1):    \n",
    "            print i,j\n",
    "        n_jw[trn_l[i]-1][j] += v_trn_matrix[i][j]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 876,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate P_jw with smoothing\n",
    "K=20\n",
    "p_jw=np.zeros([K,m])\n",
    "for j in range(K):\n",
    "    for w in range(m):\n",
    "        p_jw[j][w]=(n_jw[j][w]+1)*1.0/(nj[j+1]+m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 877,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# use logs to avoid underflow\n",
    "log_p_jw=np.zeros([K,m])\n",
    "for j in range(K):\n",
    "    for w in range(m):\n",
    "        log_p_jw[j][w]=math.log(p_jw[j][w])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 878,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the number of correctly classified: 6009\n",
      "0.199333777482\n"
     ]
    }
   ],
   "source": [
    "# test for tf-idf selctected reduced_voca\n",
    "correct_classified = 0\n",
    "for i in range(len(tst_l)):\n",
    "    predict = 0\n",
    "    max_val = float('-Inf')\n",
    "    for k in range(K):\n",
    "        tmp = log_hj[k+1]\n",
    "        tmp += np.dot(v_tst_matrix[i], log_p_jw[k])  #sum of log(P_jw ^ xi)\n",
    "\n",
    "        if tmp > max_val:\n",
    "            max_val = tmp\n",
    "            predict = k+1\n",
    "    #print \"predict\",predict\n",
    "    if predict == tst_l[i]:\n",
    "        correct_classified += 1\n",
    "    #print \"correct\", correct_classified\n",
    "print 'the number of correctly classified:', correct_classified\n",
    "print 1 - correct_classified * 1.0 / len(tst_l)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 880,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# find the largest M TF-IDF words in each class\n",
    "toplabels=np.zeros((20,20))\n",
    "topwords=[[None]*20 for i in range(20)]\n",
    "for i in range(20):\n",
    "    #find the largest 20 elements in tfidf_matrix(20x 1000)\n",
    "    toplabels[i]=np.asarray(np.argpartition(-tfidf_matrix[i],20)[:20]) \n",
    "    for j in range(20):\n",
    "        topwords[i][j]=reduced_voca[int(toplabels[i][j])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 881,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['people', 'com', 'atheism', 'writes', 'edu', 'one', 'article', 'god', 'would', 'atheists', 'islam', 'think', 'religion', 'say', 'livesey', 'like', 'morality', 'know', 'atheist', 'jesus']\n",
      "['files', 'images', 'image', 'also', 'edu', 'writes', 'software', 'would', 'file', 'graphics', 'use', 'jpeg', 'ftp', 'gif', 'one', 'data', 'com', 'format', 'know', 'like']\n",
      "['use', 'files', 'com', 'card', 'know', 'problem', 'win', 'dos', 'ei', 'file', 'like', 'one', 'windows', 'article', 'mouse', 'using', 'edu', 'writes', 'get', 'would']\n",
      "['edu', 'one', 'bios', 'scsi', 'controller', 'ide', 'card', 'drive', 'com', 'mb', 'dos', 'disk', 'drives', 'system', 'bus', 'would', 'get', 'pc', 'use', 'floppy']\n",
      "['apple', 'edu', 'mac', 'scsi', 'one', 'quadra', 'mb', 'simms', 'would', 'drive', 'nubus', 'writes', 'know', 'fpu', 'mhz', 'problem', 'centris', 'duo', 'get', 'use']\n",
      "['edu', 'widget', 'com', 'window', 'motif', 'file', 'xterm', 'use', 'program', 'server', 'get', 'output', 'lib', 'contrib', 'oname', 'entry', 'xlib', 'eof', 'one', 'printf']\n",
      "['price', 'like', 'shipping', 'new', 'sale', 'edu', 'mail', 'interested', 'good', 'asking', 'one', 'offer', 'please', 'dos', 'used', 'condition', 'com', 'wolverine', 'email', 'obo']\n",
      "['com', 'car', 'cars', 'would', 'writes', 'article', 'edu', 'one', 'get', 'like', 'good', 'engine', 'callison', 'much', 'think', 'autos', 'dealer', 'know', 'also', 'new']\n",
      "['motorcycle', 'dod', 'bikes', 'like', 'writes', 'edu', 'bike', 'com', 'ride', 'article', 'one', 'helmet', 'rider', 'would', 'get', 'bmw', 'behanna', 'riding', 'know', 'apr']\n",
      "['pitching', 'year', 'writes', 'baseball', 'edu', 'article', 'would', 'team', 'one', 'alomar', 'cubs', 'hitter', 'last', 'game', 'good', 'season', 'braves', 'rbi', 'mets', 'think']\n",
      "['team', 'players', 'ca', 'leafs', 'hockey', 'writes', 'playoffs', 'edu', 'game', 'nhl', 'flyers', 'would', 'lemieux', 'pts', 'season', 'play', 'teams', 'go', 'puck', 'islanders']\n",
      "['escrow', 'db', 'key', 'encryption', 'clipper', 'chip', 'would', 'edu', 'privacy', 'rsa', 'crypto', 'ripem', 'encrypted', 'nsa', 'one', 'com', 'government', 'keys', 'use', 'algorithm']\n",
      "['one', 'like', 'would', 'wiring', 'get', 'writes', 'edu', 'use', 'com', 'circuit', 'article', 'ground', 'know', 'amp', 'good', 'power', 'voltage', 'anyone', 'wire', 'used']\n",
      "['msg', 'like', 'candida', 'disease', 'dyer', 'people', 'com', 'would', 'article', 'patients', 'edu', 'writes', 'health', 'one', 'geb', 'also', 'hiv', 'use', 'know', 'medical']\n",
      "['lunar', 'nasa', 'writes', 'shuttle', 'edu', 'article', 'spacecraft', 'one', 'satellite', 'space', 'moon', 'would', 'launch', 'orbit', 'like', 'mars', 'earth', 'com', 'also', 'satellites']\n",
      "['bible', 'church', 'christians', 'god', 'people', 'would', 'christ', 'athos', 'one', 'think', 'jesus', 'edu', 'faith', 'christian', 'christianity', 'clh', 'know', 'believe', 'writes', 'us']\n",
      "['gun', 'would', 'weapons', 'writes', 'edu', 'article', 'right', 'militia', 'one', 'people', 'fbi', 'guns', 'firearms', 'think', 'firearm', 'get', 'com', 'handgun', 'rkba', 'like']\n",
      "['turkish', 'israeli', 'israel', 'jews', 'armenian', 'people', 'armenians', 'armenia', 'would', 'turks', 'arabs', 'article', 'edu', 'writes', 'arab', 'jewish', 'azerbaijan', 'said', 'turkey', 'one']\n",
      "['writes', 'cramer', 'stephanopoulos', 'would', 'one', 'people', 'article', 'edu', 'com', 'think', 'president', 'mr', 'government', 'know', 'optilink', 'going', 'like', 'make', 'get', 'new']\n",
      "['one', 'like', 'know', 'people', 'sandvik', 'morality', 'com', 'christ', 'christians', 'article', 'god', 'think', 'even', 'would', 'edu', 'bible', 'say', 'writes', 'christian', 'jesus']\n"
     ]
    }
   ],
   "source": [
    "for i in range(20):\n",
    "    print topwords[i]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
